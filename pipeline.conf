input {
    # Primary input for live data over http.
	http {
		host => "localhost"
		port => 8080
	}

    # Alternative input for bulk loads of data from csv.
	file {
		path => "/home/vagrant/src/elk/test_data.csv"
		start_position => "beginning"
		tags => ["csv"]
	}
}

filter {
	if "csv" in [tags] {
		csv {
			columns => ["id", "type", "csv_timestamp", "value"]
		}
		# Take object timestamp from csv_timestamp field.
		date {
			match => ["csv_timestamp", "ISO8601"]
		}

		# Drop the field as we won't need it any more.
		mutate {
			remove_field => "csv_timestamp"
		}
	} else {
		# Split http get parameters into fields.
		kv {
			field_split => "&?"
			source => "message"
		}

		# Pass only events with the valid key.
		if [key] != "asdf" {
			drop {}
		}

		# Drop the key field as we won't need it any more.
		mutate {
			remove_field => "key"
		}

		# Let only 1 event per device pass in the given time, drop others.
		# Period is in seconds.
		throttle {
			period => 10
			before_count => -1
			after_count => 1
			key => "%{id}_%{type}"
			add_tag => "throttled"
		}
		if "throttled" in [tags] {
			drop {}
		}
	}

	translate {
		add_tag => "known_device"
		destination => "location"
		dictionary_path => "/home/vagrant/src/elk/makipaa-data-logger/devices.yaml"
		exact => true
		field => "id"
		refresh_interval => 30
	}
	if "known_device" not in [tags] {
		drop {}
	}
}

output {
	elasticsearch {
		hosts => "localhost:9200"
		index => "data_logger"
		document_type => "measurement"
	}

	# For debugging, print into stdout.
	#stdout {
	#	codec => rubydebug
	#}
}
